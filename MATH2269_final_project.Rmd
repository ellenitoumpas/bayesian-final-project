---
title: MATH2269 Semester 2 2020 - Final Project

# to produce blinded version set to 1
blinded: 0

authors: 
- name: Sam Holt, Phil Steinke, Elleni Toumpas
  affiliation: RMIT
  
abstract: |
  Insert Abstract
  
keywords:
- JAGS
- multiple linear regression analysis
- prediction

bibliography: bibliography.bib
output: rticles::asa_article
fig_caption: yes
keep_tex: yes
header-includes:
 \usepackage{float}
 \floatplacement{figure}{H}
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H')
```

```{r Source Functions, message=FALSE, warning=FALSE, include=FALSE}

if (!requireNamespace('here'))
  install.packages('here')
library('here')
source(here('functions', 'functions_packages.R'))
source(here('functions', 'functions_generic.R'))
source(here('functions', 'functions_bayesian.R'))
source(here('functions', 'DBDA2E-utilities.R'))

```

```{r Packages, message=FALSE, warning=FALSE, include=FALSE}

graphics.off() # This closes all of R's graphics windows.
options(scipen = 999)
packages <- scan("requirements.txt", what="", sep="\n")
lock_n_load_libraries(packages)

```

## Introduction

## Analysis

```{r Import data, message=FALSE, warning=FALSE, include=FALSE}

data <- vroom::vroom(here('data', 'hour_extra_Brooklyn_2016_18.csv'))
data_cleaned <- data %>% janitor::clean_names()

```

```{r}

data_cleaned <- data_cleaned %>% 
  mutate(dow = factor(dow, levels = c('Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'), 
                           labels = c('Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'), ordered = TRUE), 
         winddire = factor(winddire, 
                           levels = c('N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE', 'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW','NNW'), 
                           labels = c('N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE', 'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW','NNW'),
                           ordered = TRUE))

```


### A descriptive look

#### Dimensions

```{r echo=FALSE, message=FALSE, warning=FALSE}

data.frame(columns = integer(), rows = integer()) %>%
  add_row(columns = dim(data_cleaned)[2], rows = dim(data_cleaned)[1]) %>%
  format_table(p_caption = "Dimenions")

```

```{r echo=FALSE, message=FALSE, warning=FALSE, size = 'tiny', out.extra='angle=90', size = 'tiny'}

## TODO: Find a way to hack the landscape() function so that forced page breaks dont occur. It would be good to have all preview tables
## printed in landscape so there is extra real estate in the width of the table but all header previews still contained to one page?s

source(here('src', 'data', 'inspect_data.R'))
inspect_data(data_cleaned)

```

#### Data Preprocessing

##### Removing unique identifier

```{r echo=FALSE, message=FALSE, warning=FALSE}

data_cleaned %>%
  group_by(id) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  filter(count > 1)  %>%
  format_table(p_caption = "The count of id variable filtered to show only values that are not unique.")
  
```

As confirmed above, the **id** is a unique identifier, and it is therefore removed from the dataset.

Regarding the other variables removed, we have determined $PM_{10}$ as our target variable, the remain proposed target variables ($PM_{10}a, yn_{80}, yn_{60},  yn_{50}$) are therfore discarded.

keeping: id, rainfall_mm, rf_cum_2_day - rf_cum_7_day, date_day, date_local_time, site, temperature, wd, ws, dow, hour, winddire, years, roll_temp, north, north1, weekdays, mornings,


# Data Description

| Feature                     | type    | description                                        | bayesian belief                     |
|-----------------------------|---------|----------------------------------------------------|-------------------------------------|
| id                          | double  |                                                    |                                     |
| rainfall_mm                 | double  |                                                    | medium degree                       |
| rf_cum_2_day - rf_cum_7_day | double  |                                                    |                                     |
| date_day                    | date    |                                                    |                                     |
| date_local_time             | dttm    |                                                    |                                     |
| site                        | chr     |                                                    |                                     |
| temperature                 | double  |                                                    | medium degree                       |
| pm10                        | double  | Target variable - measurement from the air station |                                     |
| pm10a                       | double  | transformed `pm10`                                 |                                     |
| wd                          | double  | Wind direction                                     | from the North with a medium degree |
| ws                          | double  |                                                    |                                     |
| dow                         | chr     |                                                    |                                     |
| hour                        | double  |                                                    | low degree of belief <br/> - the hours before peak hour are when trucks tend to focus on moving. <br/>, there is a low degree of belief             |
| winddire                    | chr     |                                                    |                                     |
| years                       | double  |                                                    |                                     |
| yn80                        | boolean | `pm10` > `80`. binary if the `pm10` hit over `80`  |                                     |
| roll_temp                   | double  |                                                    |                                     |
| yn50                        | boolean | `pm10` > `60`. if `pm10` hit over `60`             |                                     |
| north                       | boolean |                                                    |                                     |
| north1                      | boolean |                                                    |                                     |
| yn60                        | boolean | `pm10` > `50`. when `pm10` hits over `50`          |                                     |
| weekdays                    | boolean |                                                    |                                     |
| mornings                    | boolean |                                                    |                                     |

```{r echo=FALSE, message=FALSE, warning=FALSE}

data_cleaned <- data_cleaned %>% select(-id, -yn50, -yn60, -yn80, -pm10a)

```

##### Outliers

```{r echo=FALSE, message=FALSE, warning=FALSE}

ncols <- 3
nrows <- ceiling(sapply(data_cleaned, class) %>%  
                   as.data.frame() %>%
                   mutate(date_local_time = "POSIXct POSIXt", 
                          dow = "ordered factor", 
                          winddire = "ordered factor") %>%  
                   unique() %>% 
                   as.matrix() %>% 
                   t() %>% 
                   as.data.frame() %>%
                   `colnames<-`(c("class")) %>%
                   filter(class %in% c('numeric', 'integer')) %>%
                   nrow() / ncols)

fig_height <- nrows * 1.5

```

```{r echo=FALSE, fig.height=fig_height, message=FALSE, warning=FALSE}

par(mfrow = c(nrows,ncols))
par(mar=c(1,1,1,1))

for (col in colnames(data_cleaned)) {
  if ((class(data_cleaned[[col]])[1] %in% c('numeric', 'integer')) & (col != 'id')) {
    boxplot(data_cleaned[[col]], pch=19, xlab=paste0(col))
  }
}

par(mfrow=c(1,1))
par(mar=c(5.1,4.1,2.1,2.1))

```

##### Impossible values

For the numerical values in the dataset an impossible value check is performed.

<!-- ELLENI TODO: I didn't think PM10 levels could be below 0. In the impossible value check below we can see 118 records with negative PM10 levels. I need to check this with Maj Britte. For now leave as is. -->

```{r echo=FALSE, message=FALSE, warning=FALSE}

source(here('src', 'data', 'impossible_values.R'))
impossible_values(data_cleaned)

```

##### Missing values

Checking the missing values we can see that there are 23 rolling temperate missing records.

```{r echo=FALSE, message=FALSE, warning=FALSE}

data_cleaned %>%
  is.na() %>%
  colSums() %>%
  as.data.frame() %>%
  `colnames<-`(c("Number missing values")) %>%
  format_table(p_caption = "Count of missing values by variable")

```

```{r message=FALSE, warning=FALSE}

data_cleaned %>%
  filter(is.na(roll_temp)) %>%
  select(date_day, date_local_time, roll_temp, pm10) %>%
  format_table(p_caption = "Missing roll temperate values")

```

It is therefore sufficient to simply remove these records from the dataset.

```{r}

# Remove incomplete rows
data_cleaned <- data_cleaned[complete.cases(data_cleaned),]

```

##### Feature engineering

```{r}

# Do we need to create any new features from the data set?

```

##### Categorical Features

To check whether there are errors (including typos or unexpected values) in the categorical features each variable is arranged in order and then inspected by the researchers. In the list of possible values printed below there seems to be no incorrect values.

```{r message=FALSE, warning=FALSE}

for (col in colnames(data_cleaned)) {
  
  if (class(data_cleaned[[col]])[1] %in% c('factor', 'ordered', 'character')) {

    paste0("Unique values for ",col) %>% cat()
    cat("\n")

    data_cleaned %>%
      arrange(get(col)) %>%
      select(col) %>%
      unique() %>%
      pull() %>%
      as.character() %>%
      paste0(collapse = ", ") %>%
      stringr::str_trunc(width = 800, side = "right", ellipsis = "... (truncated)") %>%
      cat()

  }
}

```

##### Any categorical descriptive feature encoded

```{r message=FALSE, warning=FALSE}

### Do we need to encode categorical variables?

## Make sure we have these columns in or captured in the dataset....
# Rain 3 day
# Temperature
# WD
# WS
# day of the week
# week day/ work day/ public holiday/ weekends
# 24 hour clock hour
# change wind direction into degrees from north

holidays <- tsibble::holiday_aus(unique(data_cleaned$years), state = 'VIC')

data_cleaned <- data_cleaned %>%
  mutate(
    deg_from_north = case_when(
      wd > 180 ~ abs(wd - 360),
      TRUE ~ wd
    ),
    pre_peak_hour = case_when(
      hour > 4 & hour < 9 ~ TRUE,
      hour > 14 & hour < 17 ~ TRUE,
      TRUE ~ FALSE
    ),
    working_days = case_when(
      weekdays == TRUE ~ TRUE,
      date_day %in% holidays$date ~ FALSE,
      weekdays == FALSE ~ FALSE
    )
  )

# Base sanity checks
summary(data_cleaned$deg_from_north)
data_cleaned %>% count(hour, pre_peak_hour)
data_cleaned %>% count(working_days)

```
  
If we were to have issues within the pre_peak_hour summary, there would either be a duplicate of the hour values or NA values in both hour and pre_peak_hour fields.  
  
##### Summary statistics

A quick look at the custom summary statistics can be found below. For factors we can see the most common level, with the count of appearances for that mode level. For the Date variables we can we can see the min, max and mode levels. For the numeric and integer variables we can see the mean, median, standard deviation, minimum and maximum values.

```{r fig.cap = "Summary statistics", message=FALSE, warning=FALSE}

results_df <- exploratory_summarize(data_cleaned, col == 'id')
results_df %>%  format_table(p_caption = "Exploratory dataset")

```

##### Univariate distribution

```{r Univariate distribution, fig.cap = "A univariate look at the distribution of all the variables found in the Air dataset.", fig.height = 10, message=FALSE, warning=FALSE, fig.width=4}

plots <- list()

for (col in colnames(data_cleaned)) {
  plots[[col]] <- univariate_distribution_plot(data_cleaned[[col]], col)
}

grid.arrange(grobs = plots, ncol = 3)

```




```{r A numeric univariate vs target class distribution, fig.cap = "A ", fig.height = 15, message=FALSE, warning=FALSE, fig.width=15}

scatter_plots <- list()

for(col in colnames(data_cleaned)){
  if((class(data_cleaned[[col]])[1] %in% c('numeric','integer')) & (col != 'pm10')){
    scatter_plots[[col]] <- ggplot(data_cleaned, aes_string(x = col, y = 'pm10')) + 
      geom_point(fill = 'orange', alpha = 0.3, col = 'orange') + 
      labs(title = paste0(col," plotted\nagainst PM10 levels")) +
      assignment_multi_plot_theme
  }
}

grid.arrange(grobs = scatter_plots, ncol = 3)

```

```{r A categorical univariate vs target class distribution, fig.cap = "A ", fig.height = 15, message=FALSE, warning=FALSE, fig.width=15}

box_plots <- list()

for(col in colnames(data_cleaned)){
  if((class(data_cleaned[[col]])[1] %in% c('ordered','factor', 'character', 'logical')) & (col != 'pm10')){
    
    box_plots[[col]] <- ggplot(data_cleaned, aes_string(x = col, y = 'pm10')) + 
      geom_boxplot(fill = 'orange', alpha = 0.3, col = 'orange') + 
      labs(title = paste0(col," plotted\nagainst PM10 levels")) +
      assignment_multi_plot_theme
    
  } 
}

grid.arrange(grobs = box_plots, ncol = 3)

```

#### Likelihood

```{r, fig.cap = "PM10 Distribution", echo=FALSE, message=FALSE, warning=FALSE}

dens_plot <- ggplot(data_cleaned, aes(x = pm10)) +
  geom_density(fill = 'orange', alpha = 0.3, col = 'orange') +
  theme_bw() +
  labs(
    title = 'PM10 Distribution',
    y = 'Density',
    x = 'PM10',
    caption = 'MATH2269 - Assignment 3: Toumpas E, Steinke P, Holt S'
  ) +
  theme(
    plot.caption = element_text(face = 'italic', color = '#999999')
  ) +
  
   assignment_plot_theme

dens_plot

```

#### Correlation matrix of predictors

```{r, fig.cap= "Numeric Variable Correlation Heatmap", echo=FALSE, message=FALSE, warning=FALSE}

# Correlation Heatmap of all variables

data_cleaned_num <- data_cleaned[sapply(data_cleaned, is.numeric)]

correlations_matrix <- round(cor(data_cleaned_num), 1)

melted_cor_matrix <- reshape2::melt(correlations_matrix)

ggplot(melted_cor_matrix, aes(Var2, Var1, fill = value)) +
  geom_tile(color = "white", show.legend = F) +
  scale_fill_gradient2(
    low = "blue",
    high = "red",
    mid = "white",
    midpoint = 0,
    limit = c(-1, 1),
    space = "Lab"
  ) +
  assignment_plot_theme +
  theme(axis.text.x = element_text(
    angle = 45,
    vjust = 1,
    size = 6,
    hjust = 1
  )) +
  coord_fixed() +
  geom_text(aes(Var2, Var1, label = value),
            color = "black",
            size = 4) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.ticks = element_blank(),
    legend.justification = c(1, 0),
    legend.position = c(0.6, 0.7),
    legend.direction = "horizontal"
  ) +
  guides(fill = element_blank())

```



```{r, fig.cap = "", echo=FALSE, message=FALSE, warning=FALSE}

# Visualisation Matrix
# visual_matrix <- GGally::ggpairs(data_cleaned %>% select(rainfall_mm, rf_cum_3_day,
#                                temperature,  roll_temp,
#                                wd, ws, weekdays,
#                                pm10),
#                         aes(colour = factor(yn80)))
# visual_matrix

```



### Subsampling


features <- c('rf_cum_3_day','temperature','ws','deg_from_north','dow','working_days','hour','pre_peak_hour','pm10')
predictor_variable <- 'pm10'

train_test_split <- function(df, features, target) {
  features_ <- if(hasArg(target)) { features } else { features[-length(features)] }
  df %<>%
    mutate(pm10 = if_else(pm10 < 0, 0, pm10)) %>%
    filter(!(date_day %in% c(ymd('2018-12-28'), ymd('2018-12-29'), ymd('2018-12-30'), ymd('2018-12-31')))) %>%
    select_(.dots = features_) %>%
    mutate(dow = as.numeric(dow),
       working_days = as.numeric(working_days),
       pre_peak_hour = as.numeric(pre_peak_hour))
  return(df)
}

training_data  <- train_test_split(df=data_cleaned, features, target = predictor_variable)
prediction_data <- train_test_split(df=data_cleaned, features)


```

```{r}

# Mean specification
mu <- c(-40, 40, 0, -40, 0, 20, 0, 20)

# Variance specification
var  <- c(1/4,1/2,1/10,1/2,1/10,1/2,1/10,1/2)

# Parameters to use
use_parameters <- list(number_chains = 3, number_adaptation_steps = 200, burn_in_steps = 200, thinning_steps = 3)


```



```{r Set values for all trials}

# Select variables
predictor_variable <- 'pm10'

# Set up prediction values
xPred = array(NA, dim = c(nrow(prediction_data), length(colnames(prediction_data))))

for(i in 1:nrow(prediction_data)){
  xPred[i,] = c(prediction_data[[i,1]],	
                prediction_data[[i,2]],	
                prediction_data[[i,3]],	
                prediction_data[[i,4]],	
                prediction_data[[i,5]],	
                prediction_data[[i,6]],	
                prediction_data[[i,7]],	
                prediction_data[[i,8]])
}

# Parameters to use
use_parameters <- list(number_chains = 3, number_adaptation_steps = 200, burn_in_steps = 200, thinning_steps = 3)

```

#### Subsample size trials

```{r}

trial_type <- "subsample_size"

if(hasnt_run(trial_type)){

  # Set seeds
  seed_value <- sample(1:10000, 20, replace=F)
  write.csv(seed_value, paste0(here(),"/OUTPUTS/SEEDS/",trial_type,"_seeds.csv"), row.names = FALSE)
  
  # Set up sample size trial values
  sample_size_list <- c(100, 500, 1000, 2000, 2500, 5000)
  
  # Set up trial df and set up columns
  subsample_size_trials <- expand.grid(sampling_size = sample_size_list, seed = seed_value)
  subsample_size_trials[c(paste0(colnames(training_data),"_p_value"), "duration")] <- 0
  subsample_size_trials['trial_number'] <- 1:nrow(subsample_size_trials)

  # Added more trials later
  sample_size_list_more <- c(7500, 10000)
  subsample_size_trials_more <- expand.grid(sampling_size = sample_size_list_more, seed = seed_value)
  subsample_size_trials_more[c(paste0(colnames(training_data),"_p_value"), "duration")] <- 0
  subsample_size_trials_more['trial_number'] <- (1+nrow(subsample_size_trials)):(nrow(subsample_size_trials_more)+nrow(subsample_size_trials))
  old_n <- nrow(subsample_size_trials)
  subsample_size_trials <- rbind(subsample_size_trials,subsample_size_trials_more)
  
  
  # Run Subsampling trials
  for(row in 1:nrow(subsample_size_trials)){
    
    print(paste0('Running trial ',row))
    
    # Running subsample size trial
    returned_values <- run_subsample_trial(trial_df = subsample_size_trials, row_num = row, 
                                                              full_sample = training_data, trial_name = 'subsampling_size')
    
    returned_candidate_sample_selected <- returned_values$candidate_sample_selected
    subsample_size_trials <- returned_values$trial_df
    print('Candidate sample selected')
    
    # Deal with 0 pm10 levels
    returned_candidate_sample_selected$pm10 <- returned_candidate_sample_selected$pm10 + 0.1 
    
    # Select initial values based on candidate subsample
    sd_rf_cum_3_day <-   sd(returned_candidate_sample_selected$rf_cum_3_day)
    sd_temperature <-   sd(returned_candidate_sample_selected$temperature)
    sd_ws <-   sd(returned_candidate_sample_selected$ws)
    sd_deg_from_north <-   sd(returned_candidate_sample_selected$deg_from_north)
    sd_dow <-   sd(returned_candidate_sample_selected$dow)
    sd_working_days <-   sd(returned_candidate_sample_selected$working_days)
    sd_hour <-   sd(returned_candidate_sample_selected$hour)
    sd_pre_peak_hour <-   sd(returned_candidate_sample_selected$pre_peak_hour)
    sd_pm10 <-   sd(returned_candidate_sample_selected$pm10)
    
    initial_values_list <- c(0.1,
                             mean(returned_candidate_sample_selected$rf_cum_3_day)/sd_rf_cum_3_day, 
                             mean(returned_candidate_sample_selected$temperature)/sd_temperature, 
                             mean(returned_candidate_sample_selected$ws)/sd_ws, 
                             mean(returned_candidate_sample_selected$deg_from_north)/sd_deg_from_north, 
                             mean(returned_candidate_sample_selected$dow)/sd_dow, 
                             mean(returned_candidate_sample_selected$working_days)/sd_working_days, 
                             mean(returned_candidate_sample_selected$hour)/sd_hour,
                             mean(returned_candidate_sample_selected$pre_peak_hour)/sd_pre_peak_hour,
                             0.01)

    # Run JAGS model with candidate sample
    returned_values <- run_subsample_size_JAGS_trial(data = returned_candidate_sample_selected, 
                                                     predictor = "pm10", 
                                                     predictions = xPred, 
                                                     mu_list = mu, 
                                                     var_list = var,
                                                     initial_values = initial_values_list, 
                                                     params = use_parameters, 
                                                     trial_num = row)
    print('JAGS model run')
    
    # Save time elapsed for the model - Store
    subsample_size_trials[row, "duration"] <- returned_values['time_elapsed']
    write.csv(subsample_size_trials, paste0(here(),'/OUTPUTS/TRIAL_INFO/',trial_type,'_trials.csv'), row.names = FALSE)
  
    # Save RData 
    save.image(file = "subsample_size_trials.RData")
    
    # Reset
    graphics.off()
    
  }
  
  subsample_size_trials <- subsample_size_trials %>% 
    mutate(mean_p_value = rowMeans(subsample_size_trials[c('rf_cum_3_day_p_value', 'temperature_p_value', 'ws_p_value', 'deg_from_north_p_value', 'dow_p_value', 
                                                           'working_days_p_value', 'hour_p_value', 'pre_peak_hour_p_value', 'pm10_p_value')]))
   
  write.csv(subsample_size_trials, paste0(here(),'/OUTPUTS/TRIAL_INFO/',trial_type,'_trials.csv'), row.names = FALSE)

} else {
  
  print('Already run')
  
}

```

```{r}

subsample_size_trials <- read.csv(paste0(here(),'/OUTPUTS/TRIAL_INFO/',trial_type,'_trials.csv'), stringsAsFactors = FALSE) %>% 
  arrange(trial_number)

sample_data <- subsample_size_trials %>% 
  select(c(trial_number, sampling_size, duration, mean_p_value)) %>% 
  arrange(trial_number) %>% 
  mutate(sampling_size = factor(sampling_size, levels = c('100', '500', '1000', '2000', '2500', '5000', '7500', '10000'))) 

sample_data  %>% 
  head(25) %>% 
  format_table(p_caption = "First 25 records of the results from the subsample size trials")

```


```{r, fig.cap = "Scatter plot of all trials", echo=FALSE, message=FALSE, warning=FALSE}

ggplot(sample_data, aes(x = duration, y = mean_p_value, color = sampling_size)) +
  geom_point() +
  theme_minimal() +
  theme(legend.position = "bottom") +
  labs(x = "Model duration (sec)",
      y = "Mean p-value",
      title = "Duration of MCMC trial vs resulting mean p-value")

```

```{r}

sample_data %>% 
  group_by(sampling_size) %>% 
  summarise(mean_p_value = mean(mean_p_value), 
            mean_duration = mean(duration)) %>% 
  format_table(p_caption = "Full set of results from the subsample size trials")

```


#### Subsample selection trials

```{r}

trial_type <- "subsample_selection"

if(hasnt_run(trial_type)){

  # Set seeds
  seed_value <- sample(1:10000, 100, replace=F)
  write.csv(seed_value, paste0(here(),"/OUTPUTS/SEEDS/",trial_type,"_seeds.csv"), row.names = FALSE)
  
  # Set up sample size trial values
  sample_size_list <- c(1000)
  
  # Set up trial df and set up columns
  subsample_selection_trials <- expand.grid(sampling_size = sample_size_list, seed = seed_value)
  subsample_selection_trials[c(paste0(colnames(training_data),"_p_value"), "duration")] <- 0
  subsample_selection_trials['trial_number'] <- 1:nrow(subsample_selection_trials)
  
  # Run Subsampling trials
  for(row in 1:nrow(subsample_selection_trials)){
    
    print(paste0('Running trial ',row))
    
    # Running subsample size trial
    returned_values <- run_subsample_trial(trial_df = subsample_selection_trials, row_num = row, 
                                                              full_sample = training_data, trial_name = trial_type)
    subsample_selection_trials <- returned_values$trial_df

    # Save time elapsed for the model - Store
    write.csv(subsample_selection_trials, paste0(here(),'/OUTPUTS/TRIAL_INFO/',trial_type,'_trials.csv'), row.names = FALSE)
  
    # Save RData 
    save.image(file = "subsample_selection_trials.RData")
  }
  
  
  # When selecting all candidate subsamples, a mean p-value for each trial is calculated
   subsample_selection_trials <- subsample_selection_trials %>% 
    mutate(mean_p_value = rowMeans(subsample_selection_trials[c('rf_cum_3_day_p_value', 'temperature_p_value', 'ws_p_value', 
                                                                'deg_from_north_p_value', 'dow_p_value', 'working_days_p_value', 
                                                                'hour_p_value', 'pre_peak_hour_p_value', 'pm10_p_value')]))
   
   # These results are saved
  write.csv(subsample_selection_trials, paste0(here(),'/OUTPUTS/TRIAL_INFO/',trial_type,'_trials.csv'), row.names = FALSE)
  

} else {
  
  print('Already run')
  
}


```

```{r}

subsample_selection_trials <- read.csv(paste0(here(),'/OUTPUTS/TRIAL_INFO/',trial_type,'_trials.csv'), stringsAsFactors = FALSE) %>% 
  select('trial_number', 'mean_p_value','rf_cum_3_day_p_value', 'temperature_p_value', 'ws_p_value', 'deg_from_north_p_value', 
         'dow_p_value', 'working_days_p_value', 'hour_p_value', 'pre_peak_hour_p_value', 'pm10_p_value')

subsample_selection_trials %>% 
  arrange(desc(mean_p_value)) %>% 
  `colnames<-`(gsub("_", " ",colnames(subsample_selection_trials))) %>% 
  head(5) %>% 
  format_table(p_caption = "The top five candidate subselections in the subsample selection trials.", width = TRUE) 

```

```{r}

subsampled_data <- read.csv(paste0(here(),'/OUTPUTS/SAMPLES/SUBSAMPLE_SELECTION_TRIAL/subsample_selection_trial_candidate_subsample_7.csv'))

subsampled_data$pm10 <- subsampled_data$pm10 + 0.01

```



### Mathematical model

### Possible target variables

`pm10` is target variable
`yn80` possible target variable

### Prior specification

### Model


```{r}

# Mean specification
mu <- c(-40, 40, 0, -40, 0, 20, 0, 20)

# Variance specification
var  <- c(1/4,1/2,1/10,1/2,1/10,1/2,1/10,1/2)

# Select initial values based on candidate subsample
sd_rf_cum_3_day <- sd(subsampled_data$rf_cum_3_day)
sd_temperature <- sd(subsampled_data$temperature)
sd_ws <- sd(subsampled_data$ws)
sd_deg_from_north <- sd(subsampled_data$deg_from_north)
sd_dow <- sd(subsampled_data$dow)
sd_working_days <- sd(subsampled_data$working_days)
sd_hour <- sd(subsampled_data$hour)
sd_pre_peak_hour <- sd(subsampled_data$pre_peak_hour)
sd_pm10 <- sd(subsampled_data$pm10)
    
initial_values_list <- c(0.1,
                         mean(subsampled_data$rf_cum_3_day)/sd_rf_cum_3_day, 
                         mean(subsampled_data$temperature)/sd_temperature, 
                         mean(subsampled_data$ws)/sd_ws, 
                         mean(subsampled_data$deg_from_north)/sd_deg_from_north, 
                         mean(subsampled_data$dow)/sd_dow, 
                         mean(subsampled_data$working_days)/sd_working_days, 
                         mean(subsampled_data$hour)/sd_hour,
                         mean(subsampled_data$pre_peak_hour)/sd_pre_peak_hour,
                         0.01)

```

#### model_001_gamma_gamma_c3_a500_b500_t3

```{r}

trial_type <- "model_001_gamma_gamma_c3_a500_b500_t3"

# Parameters to use
use_parameters <- list(number_chains = 3, number_adaptation_steps = 500, burn_in_steps = 500, thinning_steps = 3)

if(hasnt_run(trial_type)){

    # Run JAGS model with candidate sample
    returned_values <- setup_run_JAGS_trial(data = subsampled_data, predictor = "pm10", predictions = xPred, mu_list = mu, 
                                            var_list = var, initial_values = initial_values_list, params = use_parameters, 
                                            par_trial_name = trial_type, num_predictions = nrow(xPred))

    # Reset
    graphics.off()

} else {
  
  print(paste0(trial_type,' already run'))
  
}

```


```{r echo=FALSE, fig.show = "hold", out.width = "50%", fig.align = "default", fig.cap= "", fig.width=10}

view_regression_diagnostics_images(trial_type)

```

```{r echo=FALSE, fig.show = "hold", out.width = "50%", fig.align = "default", fig.cap= "", fig.width = 10}

view_prediction_diagnostics_images(trial_type)

```



```{r echo=FALSE, fig.show = "hold", out.width = "50%", fig.align = "default", fig.cap= "", fig.width = 10}

view_posterior_images(trial_type)

```

```{r}

view_summary_table(trial_type) %>% format_table(p_caption="", size)

```

### Experiments to improve model efficiency

#### Isolated experiments on adapt steps

#### Isolated experiments on burn in steps

#### Isolated experiments on thinning steps

#### Isolated experiments on number of saved steps

#### Isolated experiments with initial values

### Model fine-tuning

### Prior sensitivity analysis

### Posterior Inferences

### Results

### Prediction

## Conclusion

## Reference

## Appendix
